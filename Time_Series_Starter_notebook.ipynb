{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8bxYTYZkRGTLFi004oMdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aquinate22/dsc-phase-4-project/blob/main/Time_Series_Starter_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group 4: Phase 4 Project**\n",
        "\n",
        "Members\n",
        "\n",
        "1.   Ann Gitonga\n",
        "2.   Mitchelle Okubasu\n",
        "3.   Pascal Okuda\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g-t_FEjdJ_tT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mod 4 Project - Starter Notebook\n",
        "\n",
        "This notebook has been provided to you so that you can make use of the following starter code to help with the trickier parts of preprocessing the Zillow dataset.\n",
        "\n",
        "The notebook contains a rough outline the general order you'll likely want to take in this project. You'll notice that most of the areas are left blank. This is so that it's more obvious exactly when you should make use of the starter code provided for preprocessing.\n",
        "\n",
        "**_NOTE:_** The number of empty cells are not meant to infer how much or how little code should be involved in any given step--we've just provided a few for your convenience. Add, delete, and change things around in this notebook as needed!\n",
        "\n",
        "# Some Notes Before Starting\n",
        "\n",
        "This project will be one of the more challenging projects you complete in this program. This is because working with Time Series data is a bit different than working with regular datasets. In order to make this a bit less frustrating and help you understand what you need to do (and when you need to do it), we'll quickly review the dataset formats that you'll encounter in this project.\n",
        "\n",
        "## Wide Format vs Long Format\n",
        "\n",
        "If you take a look at the format of the data in `zillow_data.csv`, you'll notice that the actual Time Series values are stored as separate columns. Here's a sample:\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/df_head.png'>\n",
        "\n",
        "You'll notice that the first seven columns look like any other dataset you're used to working with. However, column 8 refers to the median housing sales values for April 1996, column 9 for May 1996, and so on. This This is called **_Wide Format_**, and it makes the dataframe intuitive and easy to read. However, there are problems with this format when it comes to actually learning from the data, because the data only makes sense if you know the name of the column that the data can be found it. Since column names are metadata, our algorithms will miss out on what dates each value is for. This means that before we pass this data to our ARIMA model, we'll need to reshape our dataset to **_Long Format_**. Reshaped into long format, the dataframe above would now look like:\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/melted1.png'>\n",
        "\n",
        "There are now many more rows in this dataset--one for each unique time and zipcode combination in the data! Once our dataset is in this format, we'll be able to train an ARIMA model on it. The method used to convert from Wide to Long is `pd.melt()`, and it is common to refer to our dataset as 'melted' after the transition to denote that it is in long format.\n",
        "\n",
        "# Helper Functions Provided\n",
        "\n",
        "Melting a dataset can be tricky if you've never done it before, so you'll see that we have provided a sample function, `melt_data()`, to help you with this step below. Also provided is:\n",
        "\n",
        "* `get_datetimes()`, a function to deal with converting the column values for datetimes as a pandas series of datetime objects\n",
        "* Some good parameters for matplotlib to help make your visualizations more readable.\n",
        "\n",
        "Good luck!\n",
        "\n",
        "\n",
        "# Step 1: Load the Data/Filtering for Chosen Zipcodes"
      ],
      "metadata": {
        "id": "Hd9seLIcJ5gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "br5epe4JNY3s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "data = pd.read_csv('')"
      ],
      "metadata": {
        "id": "ootRb2efKqup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lwiYtv-0OXzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BR5Z68bbKr2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnbkOqB-KtSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Preprocessing"
      ],
      "metadata": {
        "id": "XT_DvIxuKxbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datetimes(df):\n",
        "    \"\"\"\n",
        "    Takes a dataframe:\n",
        "    returns only those column names that can be converted into datetime objects\n",
        "    as datetime objects.\n",
        "    NOTE number of returned columns may not match total number of columns in passed dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    return pd.to_datetime(df.columns.values[1:], format='%Y-%m')"
      ],
      "metadata": {
        "id": "H7OapYyWJ9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_lcbthkLC2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoNEU7gBLGdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "raROehnwLGqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: EDA and Visualization"
      ],
      "metadata": {
        "id": "Yd6P5L-gLH9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "font = {'family' : 'normal',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "# NOTE: if you visualizations are too cluttered to read, try calling 'plt.gcf().autofmt_xdate()'!"
      ],
      "metadata": {
        "id": "IU_hq_SILLaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "virVwb_VLQve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDnW6uZxLQ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRGcp9IsLQ6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Reshape from Wide to Long Format"
      ],
      "metadata": {
        "id": "2bexcQbWLTsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def melt_data(df):\n",
        "    \"\"\"\n",
        "    Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.\n",
        "    Returns a long-form datetime dataframe\n",
        "    with the datetime column names as the index and the values as the 'values' column.\n",
        "\n",
        "    If more than one row is passes in the wide-form dataset, the values column\n",
        "    will be the mean of the values from the datetime columns in all of the rows.\n",
        "    \"\"\"\n",
        "\n",
        "    melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank', 'City', 'State', 'Metro', 'CountyName'], var_name='time')\n",
        "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
        "    melted = melted.dropna(subset=['value'])\n",
        "    return melted.groupby('time').aggregate({'value':'mean'})"
      ],
      "metadata": {
        "id": "4m2KbgEmLQ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JzYwzXj4MzVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEn87_P6MzKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jypRrGmUMy7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: ARIMA Modeling"
      ],
      "metadata": {
        "id": "FBeSWtTxM2Su"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLFHdrJtNBFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxS4DeyTNA8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n55QyIDWNAxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Interpreting Results"
      ],
      "metadata": {
        "id": "_y5L6cqkM8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5f_uV6MM7iN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
